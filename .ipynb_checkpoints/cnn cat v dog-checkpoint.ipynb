{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1852fe3-7371-40e9-a4bc-a26fc4694cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41103219-0e10-42af-8b98-9134dd383b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4790c24-ea14-46bd-9573-af46d82d86e6",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194432e1-0115-476a-8211-c6fbf8ff3028",
   "metadata": {},
   "source": [
    "Apply transformation on training set to reduce overfitting (Image Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3af2ea6-9d7c-4f87-b3c2-8435773f444e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    \"dataset/training_set\",\n",
    "    target_size=(64,64),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f06b1a6-bacc-4a04-ad21-8187f40024ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "testing_set = test_datagen.flow_from_directory(\n",
    "    \"dataset/test_set\",\n",
    "    target_size=(64,64),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95e11bb-280d-41dc-a3cf-71551e38e970",
   "metadata": {},
   "source": [
    "## Part 2: Building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8eef053-2a1b-4151-8c53-523bae386360",
   "metadata": {},
   "source": [
    "Initializing the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "344fd368-0181-4e08-ae39-6347bc993993",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a7961e-e3d8-41b4-b18d-af43646fcf57",
   "metadata": {},
   "source": [
    "Step 1: Convolution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da5a739b-aa8f-4fda-bb90-d9f7ffb6899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\", input_shape=[64,64,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776b793f-f16c-4ff7-b00d-dbd5cead4f3b",
   "metadata": {},
   "source": [
    "Step 2: Pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac7fec52-1152-454d-afc6-40bd0e148f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a12e7e-9e96-424f-aebc-743d017458a3",
   "metadata": {},
   "source": [
    "Add a second convolution and pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2cd5f98-f4f7-486f-aa32-93309c711b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\"))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a813d23-c0ac-4111-86f5-a25aaa145409",
   "metadata": {},
   "source": [
    "Step 3: Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c599b4de-b79e-46aa-929f-d57cb0455ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71632242-072c-4116-871d-98c581625264",
   "metadata": {},
   "source": [
    "Step 4: Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dce08d2d-9675-450a-81c3-a86dc54d8366",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cf1c157-173f-44a2-993b-1c211f2f2cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf09ecc-7455-45f4-9c7c-0003472a76de",
   "metadata": {},
   "source": [
    "## Part 3: Training the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7019c7-e406-49d2-b9a8-8c00450dd363",
   "metadata": {},
   "source": [
    "Compiling the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e52765b-6728-4919-a818-4a9d68a03304",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d64a5c6-3e30-4efd-85e5-6bf9ef41b661",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - 169s 668ms/step - loss: 0.6709 - accuracy: 0.5888 - val_loss: 0.6712 - val_accuracy: 0.5805\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 20s 81ms/step - loss: 0.6060 - accuracy: 0.6726 - val_loss: 0.5715 - val_accuracy: 0.7125\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 20s 80ms/step - loss: 0.5755 - accuracy: 0.6949 - val_loss: 0.5516 - val_accuracy: 0.7235\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 20s 81ms/step - loss: 0.5429 - accuracy: 0.7180 - val_loss: 0.6029 - val_accuracy: 0.6700\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 20s 81ms/step - loss: 0.5125 - accuracy: 0.7475 - val_loss: 0.5058 - val_accuracy: 0.7550\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 20s 82ms/step - loss: 0.4874 - accuracy: 0.7601 - val_loss: 0.4952 - val_accuracy: 0.7690\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 20s 82ms/step - loss: 0.4676 - accuracy: 0.7731 - val_loss: 0.5054 - val_accuracy: 0.7595\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 20s 81ms/step - loss: 0.4552 - accuracy: 0.7847 - val_loss: 0.4929 - val_accuracy: 0.7690\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 20s 81ms/step - loss: 0.4317 - accuracy: 0.7936 - val_loss: 0.4647 - val_accuracy: 0.7865\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 20s 81ms/step - loss: 0.4235 - accuracy: 0.7979 - val_loss: 0.4667 - val_accuracy: 0.7885\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 20s 81ms/step - loss: 0.4155 - accuracy: 0.8070 - val_loss: 0.5054 - val_accuracy: 0.7625\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 20s 81ms/step - loss: 0.3946 - accuracy: 0.8192 - val_loss: 0.4774 - val_accuracy: 0.7755\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 20s 82ms/step - loss: 0.3891 - accuracy: 0.8226 - val_loss: 0.4674 - val_accuracy: 0.7895\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 20s 82ms/step - loss: 0.3715 - accuracy: 0.8349 - val_loss: 0.4699 - val_accuracy: 0.7885\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 22s 86ms/step - loss: 0.3561 - accuracy: 0.8419 - val_loss: 0.4584 - val_accuracy: 0.8005\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 20s 79ms/step - loss: 0.3494 - accuracy: 0.8350 - val_loss: 0.4496 - val_accuracy: 0.8175\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 20s 82ms/step - loss: 0.3275 - accuracy: 0.8562 - val_loss: 0.5172 - val_accuracy: 0.7765\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 20s 81ms/step - loss: 0.3286 - accuracy: 0.8534 - val_loss: 0.4628 - val_accuracy: 0.8020\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 20s 81ms/step - loss: 0.3035 - accuracy: 0.8675 - val_loss: 0.5200 - val_accuracy: 0.8005\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 22s 86ms/step - loss: 0.2906 - accuracy: 0.8683 - val_loss: 0.4941 - val_accuracy: 0.7970\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 21s 82ms/step - loss: 0.2755 - accuracy: 0.8846 - val_loss: 0.5117 - val_accuracy: 0.7970\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 21s 82ms/step - loss: 0.2685 - accuracy: 0.8894 - val_loss: 0.5292 - val_accuracy: 0.7965\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 21s 83ms/step - loss: 0.2568 - accuracy: 0.8911 - val_loss: 0.5087 - val_accuracy: 0.8065\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 21s 82ms/step - loss: 0.2386 - accuracy: 0.9000 - val_loss: 0.5193 - val_accuracy: 0.8035\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 21s 84ms/step - loss: 0.2379 - accuracy: 0.9016 - val_loss: 0.5169 - val_accuracy: 0.8050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bee26b7548>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x=training_set, validation_data=testing_set, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6abe870a-c3cd-4dd3-a35d-0d4930167fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn_model\\assets\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "cnn.save(\"cnn_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5857bc40-0617-449b-923e-9db25ae1d381",
   "metadata": {},
   "source": [
    "## Making a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7974333-3760-400b-ac13-c66908fd4f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "cnn = tf.keras.models.load_model('cnn_model')\n",
    " \n",
    "\n",
    "test_image = image.load_img(\"dataset/single_prediction/cat_or_dog_2.jpg\", target_size=(64,64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "result = cnn.predict(test_image/255.0)\n",
    "\n",
    "# training_set.class_indices\n",
    "\n",
    "if result[0][0] > 0.5:\n",
    "    prediction = \"dog\"\n",
    "else:\n",
    "    prediction = \"cat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89f3be28-408d-4aa8-a752-c6dba873c2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b6b37c-4e29-4942-be22-40460922e769",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37gpu",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
